# 2026-01-24

## 今日やったこと

### Terraform構成の実績ベースへの修正

昨日作成したTerraform構成を、ユーザーの別プロジェクト（ai-assistant-scheduler）の実績ある構成に合わせて修正した。

主な変更点:
- ディレクトリ名: `terraform/` → `infra/`
- Cloudflare provider: `~> 4.0` → `~> 5.1`
- Terraform version: `1.7.0` → `1.10`
- 環境分離: workspace → stg/prod両方を同一tfファイルで定義
- Workers Script: Terraform管理から削除（wranglerに任せる）
- D1に `lifecycle { ignore_changes = all }` を追加

最初に作った構成はworkspaceで環境分離する設計だったが、実績構成はstg/prodリソースを両方定義するシンプルな方式だった。実績があるなら素直にそれに従うのが正解。

### CI/Deploy ワークフローの作成

ai-assistant-schedulerを参考に、以下を作成:

- `ci.yml`: PR時の変更検出 + テスト + 型チェック
- `deploy.yml`: master push → staging、手動 → 選択可

参考にしたポイント:
- `dorny/paths-filter` で変更検出（無駄なジョブをスキップ）
- `printenv` でシークレットをwranglerに渡す（プロセスリスト露出回避）
- GitHub Environment Variables で環境別設定を管理
- Apply後のoutput表示

### wrangler.toml の環境設定追加

api/web両方のwrangler.tomlにstaging/production環境設定を追加。webはWorkers Static Assetsで静的サイト配信する構成。

### セットアップガイドの作成

ユーザーが手動でやる必要がある作業をチェックリスト形式でまとめた（`docs/setup-guide.md`）。最初は説明文形式で書いたが、ユーザーから「チェックリスト形式で」とリクエストがあり書き直した。

## 反省

最初のTerraform構成で独自設計をしてしまった。ユーザーに「別プロジェクトで動いてる構成がある」と言われて初めて確認した。最初から「既存で動いてる構成はありますか？」と聞くべきだった。

セットアップガイドも最初は説明文ベースで書いた。ドキュメントの目的（手順を追って実行する）を考えれば、チェックリスト形式の方が適切だった。「誰がどう使うか」を先に考えるべき。

## 学び

- 実績ある構成があるなら、まずそれを確認して合わせる
- ドキュメントは「誰がどう使うか」で形式を決める
  - 手順書 → チェックリスト
  - 解説 → 説明文
- CI/CDの設計は、実際に動いてるプロジェクトを参考にするのが効率的

## 雑感

今日はほぼインフラ・CI/CD周りの作業だった。アプリケーションコードを書くより、こういう基盤整備の方が地味だけど重要。ユーザーが「まだ環境用意するつもりない」と言っていたので、masterへのpush時のデプロイは無効化しておいた。準備が整ったらコメントを外すだけで有効化できる。

---

## セキュリティレビューと改善（夜）

### やったこと

ユーザーから「セキュリティレビューしてほしい」と依頼があり、ExploreエージェントとCodex CLIの2つで並行レビューを実施した。

**発見したCritical問題:**
1. CORS全開放（`cors()` デフォルト設定）
2. 開発モード認証バイパスが本番で有効になる可能性
3. JWTトークンをlocalStorageに保存（XSSで盗まれる）
4. JWT SECRET強度検証なし

**実施した修正:**

1. **環境変数の整理**: `AUTH_MODE` → `ENVIRONMENT`（local/staging/production）
   - 「認証モード」ではなく「動作環境」として分離
   - localのみ認証バイパス許可、stg/prodでは不可能に

2. **CORS設定**: 環境に応じて動的設定
   - local: 全許可
   - stg/prod: `WEB_BASE_URL`のみ許可

3. **JWT周りの大改修**:
   - アクセストークン: 15分、インメモリ保持
   - リフレッシュトークン: 30日、HttpOnly Cookie、DBにハッシュ保存
   - refresh_tokensテーブル新規作成
   - フロントエンド: リロード時・401時に/refresh呼び出し

### 反省

Codexが発見した「メッセージ評価の認可漏れ」は、Exploreエージェントでは検出できなかった。2つのツールで並行レビューしたのは正解だった。片方だけだと見落としがあった。

JWT周りの改修は結構大規模になった。最初からアクセストークン/リフレッシュトークン分離で設計しておけば良かったが、後から直すことになった。セキュリティは後付けより最初から考えるべき、という典型例。

### 学び

- セキュリティレビューは複数の視点で行う価値がある
- 環境変数は「何のための設定か」を明確にする命名が重要
  - `AUTH_MODE=dev` より `ENVIRONMENT=local` の方が意図が明確
- トークン設計はSPA開発の初期段階で決めるべき
  - アクセストークン: 短命、メモリ
  - リフレッシュトークン: 長命、HttpOnly Cookie
  - この構成は後から変更するとフロントエンド全体に影響する

### 雑感

ユーザーとの対話で「AUTH_MODEじゃなくて純粋に動作環境としてstg/prodが分かる方が良いね」という提案があった。これは良い指摘だった。自分は「認証モード」と「動作環境」を混同した設計をしていた。

リフレッシュトークンのDB保存について「usersテーブルとは別にテーブル切り出して」という要件も明確で助かった。最初は同じテーブルに入れようかと思ったが、分離した方がセッション管理（複数デバイス対応、強制ログアウト等）が柔軟にできる。

---

## セキュリティレビュー残項目の対応（夜2）

### やったこと

先ほどのセキュリティレビューで作成した `docs/security-review.md` のHigh/Medium/Low項目を対応。

**対応した項目:**

| 重大度 | 項目 | 対応内容 |
|--------|------|----------|
| High | 認可漏れ（メッセージ評価） | `getMessageForEvaluation`にuserId追加、セッション経由で所有権チェック |
| High | 入力サイズ制限なし | Zodスキーマにmax制限追加（content: 10000, userMemo: 50000, 配列: 50件など） |
| High | MIME Typeバリデーション | `z.enum(["image/jpeg", "image/png", "image/gif", "image/webp"])` |
| High | ファイル名サニタイゼーション | `sanitizeFilename`関数追加、パストラバーサル防止 |
| Medium | エラー情報漏洩 | Google OAuthのエラーメッセージを抽象化（内部ログは保持） |
| Medium | R2キーからユーザーID除去 | `images/${userId}/${imageId}/${filename}` → `images/${imageId}/${safeFilename}` |
| Low | 依存パッケージ監査 | `pnpm audit`スクリプト追加 |
| Low | AIエラー処理 | ストリーミング中のエラーをtry-catchでキャッチしてユーザーに通知 |

**スキップした項目:**
- レート制限（ユーザー判断でスキップ、KV設定が必要でヘビー）
- セッションテーブル（大規模変更）
- OCR暗号化（大規模変更）
- Google OAuth ID Token検証（大規模変更）

### 反省

プランモード使用時、最初はシステムが指定するパス（`C:\Users\...\.claude\plans\`）にプランファイルを作ってしまった。ユーザーから「planファイルは必ずdocs/以下に」と指摘されて `docs/plan/security-fix-plan.md` に書き直した。プロジェクトのドキュメント規約を確認すべきだった。

### 学び

- 入力バリデーションは「何を許可するか」を明示的に定義する
  - 文字列長: max制限
  - ファイル形式: enumでホワイトリスト
  - 配列: 要素数と各要素の長さ両方を制限
- ファイル名サニタイズは多層防御で
  - Zodスキーマで一次フィルタ
  - usecase層でサニタイズ関数を通す
- R2キーにユーザーIDを含めない
  - DBで関連付けを管理すれば十分
  - キーからユーザーを推測させない

### 雑感

セキュリティ修正は地味だが重要な作業だった。認可漏れ（IDOR）は「他ユーザーのリソースに直接アクセスできる」という典型的な脆弱性で、見落としがちだが影響は大きい。今回はセキュリティレビューで発見できて良かった。

レート制限をスキップしたのはユーザーの判断だが、個人的には早めに対応した方が良いと思う。AI API呼び出しのあるエンドポイントは、悪意のある連続リクエストでコストが跳ね上がるリスクがある。ただ、KV設定が必要になるのは確かに面倒なので、優先度の判断としては理解できる。

---

## セキュリティ追加対応（夜3）

### やったこと

ユーザーとのディスカッションで、当初「スキップ」としていた項目のうち2つが実は対応可能または対応済みだと判明し、追加実装した。

**M1. セッション管理**

最初は「セッションテーブルなし」として大規模変更扱いにしていたが、ユーザーから指摘を受けた：

> 「リフレッシュトークンを別テーブルで切り出してることによって比較的実現しやすくないか？ログイン時に新規作成、ログアウトで削除、これで各デバイス独立のセッションになってるでしょ」

その通りだった。refreshTokensテーブルがすでにセッション管理の役割を果たしている。各デバイスは独立したリフレッシュトークンを持ち、ログアウトしても他デバイスに影響しない。「対応済み」に変更。

**M6. Google OAuth ID Token検証**

最初は「joseライブラリ追加やJWKS取得が必要で大規模」と判断していたが、ユーザーから「本当に大規模？」と問われて再考した。

実際にやってみると：
1. `jose`パッケージ追加
2. `OAuthTokens`型に`id_token`フィールド追加
3. `getUserInfo`の引数を`tokens`全体に変更
4. google.tsでID Token検証を実装

変更ファイルは4つ、型チェックも一発で通った。「大規模変更」というほどではなかった。

### 反省

「大規模変更だからスキップ」という判断が2件とも間違っていた。

M1は、既存の実装を正しく理解していなかった。refreshTokensテーブルの設計意図を考えれば、セッション管理は実現済みだと気づくべきだった。

M6は、実装する前に「大変そう」と決めつけていた。実際にやってみたら1ファイル内でほぼ完結する変更だった。見積もりが保守的すぎた。

教訓：「大規模変更だからスキップ」と言う前に、実際の変更量を見積もるべき。

### 学び

- 既存実装の設計意図を理解することが重要
  - refreshTokensを「リフレッシュトークン保存用」としか見ていなかった
  - 実際は「デバイス単位のセッション管理」という役割も持っている
- 「大規模変更」かどうかは、実装を検討してから判断すべき
  - 漠然と「ライブラリ追加が必要だから大変」と思い込まない
  - 具体的な変更箇所を列挙してみる
- OIDC ID Token検証のパターン
  - `jose.createRemoteJWKSet`でGoogle公開鍵を取得
  - `jose.jwtVerify`でissuer/audience検証付きで署名検証
  - Cloudflare Workersでも問題なく動作

### 最終状況

security-review.mdの19項目中：
- 対応済み: 17件
- スキップ: 2件（レート制限、OCR暗号化）

レート制限はKV設定が必要で実装規模が大きいため、別セッションで対応予定。OCR暗号化は試験問題のテキストなので優先度低としてスキップ。

---

## 動作検証とCORS/認証フローの修正（夜4）

### やったこと

ユーザーから「Chromeで実際に動作確認して」と依頼があり、ブラウザで画面遷移をテストした。

**発生した問題と修正:**

1. **CORSエラー（503）**

   最初、`/api/subjects` が503を返していた。curlでは動くのにブラウザからは失敗。原因は：
   - フロントエンド: `credentials: 'include'` を使用
   - サーバー: `cors()` デフォルト設定で `Access-Control-Allow-Origin: *`
   - この組み合わせはブラウザが拒否する

   修正: CORS設定を動的オリジン判定に変更
   ```typescript
   origin: (origin) => {
     if (env.ENVIRONMENT === "local") {
       // localhost, 127.0.0.1, プライベートIP を許可
       if (host === "localhost" || host.startsWith("192.168.") || ...) {
         return origin // リクエスト元をそのまま返す
       }
     }
     return env.WEB_BASE_URL
   }
   ```

2. **開発モードの認証バイパスが強すぎる問題**

   ユーザーから指摘：「開発モードでトークンフローが全然検証できてない」

   問題点：
   - フロントエンドの `handleDevLogin` が `setDevAuth()` を呼ぶだけ
   - サーバーにリクエストを送らず、リフレッシュトークンも発行されない
   - セキュリティレビューで実装したトークンの仕組みがテストできない

   修正:
   - サーバー: `/api/auth/dev-login` エンドポイント追加（ローカル環境のみ）
   - 本番と同じフローでアクセストークン + リフレッシュトークンを発行
   - フロントエンド: `devLogin()` 関数を追加、APIを呼ぶように変更
   - `setDevAuth()`, `dev-token` による認証バイパスを削除

3. **ログアウトがAPIを呼んでいない**

   `Header.tsx` で `clearAuth` を呼んでいただけで、`/api/auth/logout` を呼んでいなかった。
   → `logout` 関数を使うように修正

**検証結果:**
- ✅ 開発ログイン → アクセストークン + リフレッシュトークン発行
- ✅ リロード → リフレッシュトークンでアクセストークン再取得（200）
- ✅ ログアウト → DBからトークン削除 + Cookie削除（200）
- ✅ ログアウト後リロード → リフレッシュ失敗（401）

### 反省

「開発モードで認証をバイパス」という設計自体は開発効率のためだったが、セキュリティ実装を検証できないという重大な欠点があった。ユーザーに指摘されるまで気づかなかった。

「APIヘッダーによる認証バイパスはそのまま」というユーザーの要件は的確だった。curlでのテストには便利だが、フロントエンドからの通常フローでは本番と同じ認証を通る設計。開発効率とセキュリティ検証のバランスが取れている。

### 学び

- 開発モードのバイパスは「何をバイパスするか」を慎重に選ぶ
  - 認証ヘッダーのバイパス（API直接テスト用）: OK
  - トークン発行フローのバイパス: セキュリティ検証ができなくなる
- `credentials: 'include'` と `Access-Control-Allow-Origin: *` は共存できない
  - ブラウザのセキュリティポリシー
  - 動的にオリジンを返す必要がある
- 実装後は必ずブラウザで動作確認
  - curlで動いてもブラウザで動くとは限らない
  - CORS、Cookie、認証の組み合わせは複雑

### 雑感

今日はセキュリティ関連の作業が多かった。朝のTerraform/CI、昼のセキュリティレビュー、夜の修正・検証と、一日で基盤周りが大きく進んだ。

ユーザーの「開発ログインでリフレッシュトークン生成されてるか調べて」という一言で問題に気づけた。自分一人だと「開発モードだから動いてる」で済ませていた可能性がある。実装を検証するテストの重要性を再認識した。

---

## セキュリティ修正の統合レビューと追加対応（夜5）

### やったこと

ユーザーから「セキュリティレビュー報告書の修正が一通り終わったので、再度レビューして」と依頼があり、3つの並行タスクを実行した。

1. **Explore Agent**: 実装状況の詳細確認（12項目チェック）
2. **Codex CLI**: 独立したセキュリティ観点でのレビュー
3. **ペネトレーションテスト**: 報告書を知らせず攻撃者視点で検証

3つ目のアプローチは面白かった。既知の脆弱性情報を与えずに「攻撃者として振る舞え」と指示することで、見落としがないかを検証できる。

**発見された残存問題（6件）:**

| 優先度 | 問題 | 対応 |
|--------|------|------|
| High | 画像サイズ制限なし | 10MB制限追加 |
| High | MIMEバリデーション未適用 | `z.enum(allowedMimeTypes)`使用 |
| High | JWT SECRET検証が警告のみ | `throw new Error`に変更 |
| Medium | セキュリティヘッダー不足 | `secureHeaders()`ミドルウェア追加 |
| Medium | マジックバイト検証なし | `validateMagicBytes()`実装 |
| Medium | 環境変数バリデーション不足 | `validateEnv()`追加 |

**発見したバグ:**

`createUploadUrl`で生成した`imageId`と、`repository.create`内部で生成する`id`が別々だった。curlでアップロードテストすると「Image not found」になる既存バグ。

### 動作確認

```
1. サイズ制限: 11MB → 413 File too large ✅
2. MIMEバリデーション: text/plain → 400 Invalid enum ✅
3. マジックバイト検証: ゼロファイル → 400 Invalid file format ✅
4. セキュリティヘッダー: X-Frame-Options等追加 ✅
```

### 反省

curlでのテストで最初パイプ経由のデータ送信がうまくいかなかった（`dd | curl --data-binary @-`）。Windows環境の問題。テンポラリファイルを作成してから送信することで解決したが、環境差異は事前に把握しておくべき。

「Image not found」エラーが出た時点で、もっと早くDBへの保存を疑うべきだった。結局、usecaseとrepositoryのID不一致という単純なバグだった。

### 学び

- 複数の視点でのセキュリティレビューは価値がある
  - Exploreで見落としたものをCodexが発見
  - ペンテストで実際の攻撃耐性を検証
- マジックバイト検証でファイル形式を実際に確認
  - MIMEタイプはクライアントが自己申告できる
  - ファイル先頭バイトで実形式を検証
- テストがないとバグが長期間残る
  - imageId不一致バグは以前から存在していた可能性
  - E2Eテストがあれば発見できていた

### 雑感

今日一日でセキュリティ周りが大きく進んだ。朝のTerraform/CI、昼のセキュリティレビュー、夜の修正・検証、そして今回の統合レビュー。

ユーザーから「curlでAPI叩くのはバイパス用意されてない？」と聞かれて、ローカル環境での認証スキップの仕組みを説明した。こういう「すでに実装されている機能」をユーザーが把握していないケースは多い。ドキュメントに書くべきだろうか。

レート制限とOCR暗号化は意図的にスコープ外。ユーザーの判断を尊重しているが、レート制限は早めに対応した方がいいと個人的には思う。AI APIのコスト爆発リスクがある。
